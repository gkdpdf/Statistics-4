{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bea1951-c8b9-4363-a4a1-7a1d5ba4fd24",
   "metadata": {},
   "source": [
    "1. Probability mass function denotes the probability that a discrete random variable will take on a particular value. Probability density function gives the probability that a continuous random variable will lie between a certain specified interval. It is used for discrete random variables\n",
    "\n",
    "ex : PMF : Head/Tails probability \n",
    "    PDF : Height probability in the class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f31297-e4bf-48ed-98f2-23fa2edd7ce8",
   "metadata": {},
   "source": [
    "2. Cumulative Distribution Function (CDF), of a real-valued random variable X, evaluated at x, is the probability function that X will take a value less than or equal to x. It is used to describe the probability distribution of random variables in a table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39743b2-b4f6-4c92-8477-838a973839a1",
   "metadata": {},
   "source": [
    "3. \n",
    "Height and Weight of a Population:\n",
    "IQ Scores:\n",
    "Test Scores:\n",
    "It changed as per the mean and std deviation.\n",
    "Mean if shifts right or left then peak will also moves from the peak\n",
    "std. deviation will decide the spread of the bell curve ,if it is larger then bell curve more flat and if it is too narrow then it will be more taller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24638fd-f0c7-4294-913c-62ffeda41bc9",
   "metadata": {},
   "source": [
    "4.\n",
    "The normal distribution is of great importance in statistics and various fields due to its mathematical properties and its prevalence in describing the distribution of many natural phenomena. Here are some reasons why the normal distribution is important:\n",
    "\n",
    "**Central Limit Theorem**:\n",
    "\n",
    "The normal distribution plays a central role in the Central Limit Theorem, which states that the distribution of the sum (or average) of a large number of independent, identically distributed random variables approaches a normal distribution, regardless of the shape of the original distribution. This makes the normal distribution a key concept in statistical inference and hypothesis testing.\n",
    "Statistical Inference:\n",
    "\n",
    "Many statistical methods, such as hypothesis testing and confidence intervals, rely on the assumption that the data follows a normal distribution. This assumption simplifies statistical analyses and makes them more tractable.\n",
    "**Parameter Estimation:\n",
    "\n",
    "Maximum Likelihood Estimation (MLE) and other statistical estimation methods often assume normality, making the normal distribution a convenient choice for parameter estimation in various models.\n",
    "**Quality Control:\n",
    "\n",
    "In manufacturing and quality control, the normal distribution is often used to model the distribution of product characteristics. Deviations from normality can signal potential issues in the production process.\n",
    "**Finance and Economics:\n",
    "\n",
    "The normal distribution is frequently used in financial modeling, especially in the context of portfolio theory and option pricing (e.g., Black-Scholes model). Stock prices and returns are often assumed to follow a normal distribution in these models.\n",
    "**Biostatistics and Medicine:\n",
    "\n",
    "In medical research, many biological measurements, such as blood pressure, cholesterol levels, and body temperatures, often exhibit a distribution that is approximately normal. This makes the normal distribution a valuable tool in analyzing and interpreting clinical data.\n",
    "**Psychology and Education:\n",
    "\n",
    "IQ scores and various psychological traits are often assumed to be normally distributed. This assumption is foundational in educational testing and psychological research.\n",
    "Demography:\n",
    "\n",
    "Population characteristics, such as age distribution and income distribution, are often modeled using the normal distribution. This simplifies demographic analyses and predictions.\n",
    "Real-life examples of normal distribution:\n",
    "\n",
    "-Heights of Individuals:\n",
    "\n",
    "The distribution of human heights in a population often follows a normal distribution.\n",
    "-Exam Scores:\n",
    "\n",
    "In educational settings, the scores on standardized tests are often assumed to be normally distributed.\n",
    "-Reaction Times:\n",
    "\n",
    "The time it takes for individuals to react to a stimulus is often modeled using a normal distribution.\n",
    "-Monthly Rainfall:\n",
    "\n",
    "In some regions, the monthly rainfall amounts can be approximately normally distributed.\n",
    "-Errors in Measurements:\n",
    "\n",
    "Measurement errors in scientific experiments are often assumed to be normally distributed.\n",
    "-Wait Times:\n",
    "\n",
    "The time people spend waiting in a queue, such as at a checkout counter, can often be modeled using a normal distribution.\n",
    "While the normal distribution is a powerful and widely used tool, it's important to note that not all real-world data perfectly follows a normal distribution. In practice, deviations from normality are common, and other statistical distributions may be more appropriate for specific situations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b80c2c-0d3f-4f97-81e3-5a1fad4398e6",
   "metadata": {},
   "source": [
    "5.\n",
    "The Bernoulli distribution is a discrete probability distribution that models a random experiment with two possible outcomes: success (usually denoted as \\(1\\)) and failure (usually denoted as \\(0\\)). It is named after Jacob Bernoulli, a Swiss mathematician. The probability mass function (PMF) of the Bernoulli distribution is given by:\n",
    "\n",
    "\\[ P(X = x) = p^x \\cdot (1-p)^{1-x} \\]\n",
    "\n",
    "where:\n",
    "- \\(X\\) is a random variable representing the outcome (success or failure).\n",
    "- \\(p\\) is the probability of success.\n",
    "- \\(1-p\\) is the probability of failure.\n",
    "\n",
    "The expected value (mean) of the Bernoulli distribution is \\(E(X) = p\\), and its variance is \\(Var(X) = p(1-p)\\).\n",
    "\n",
    "**Example of Bernoulli Distribution:**\n",
    "Consider a single coin flip where \"Heads\" is considered a success (\\(X = 1\\)) and \"Tails\" is a failure (\\(X = 0\\)). The probability of getting a \"Heads\" might be \\(p = 0.5\\). In this case, the Bernoulli distribution models the probability of success (getting \"Heads\") on a single coin flip.\n",
    "\n",
    "---\n",
    "\n",
    "The Binomial distribution, on the other hand, is a discrete probability distribution that describes the number of successes in a fixed number of independent Bernoulli trials, each with the same probability of success (\\(p\\)). In other words, while the Bernoulli distribution models a single trial, the Binomial distribution models the number of successes in a fixed number of trials.\n",
    "\n",
    "The probability mass function (PMF) of the Binomial distribution is given by:\n",
    "\n",
    "\\[ P(X = k) = \\binom{n}{k} \\cdot p^k \\cdot (1-p)^{n-k} \\]\n",
    "\n",
    "where:\n",
    "- \\(X\\) is the number of successes.\n",
    "- \\(n\\) is the number of trials.\n",
    "- \\(k\\) is the number of successes.\n",
    "- \\(p\\) is the probability of success in each trial.\n",
    "- \\(\\binom{n}{k}\\) is the binomial coefficient, representing the number of ways to choose \\(k\\) successes from \\(n\\) trials.\n",
    "\n",
    "The expected value (mean) of the Binomial distribution is \\(E(X) = np\\), and its variance is \\(Var(X) = np(1-p)\\).\n",
    "\n",
    "**Difference between Bernoulli Distribution and Binomial Distribution:**\n",
    "\n",
    "1. **Number of Trials:**\n",
    "   - The Bernoulli distribution models a single trial, while the Binomial distribution models the number of successes in a fixed number of independent trials.\n",
    "\n",
    "2. **Random Variables:**\n",
    "   - The Bernoulli distribution has one random variable, representing the outcome of a single trial (success or failure). The Binomial distribution has a discrete random variable representing the number of successes in a fixed number of trials.\n",
    "\n",
    "3. **Probability Mass Function:**\n",
    "   - The PMF of the Bernoulli distribution is simpler, as it deals with a single trial. The PMF of the Binomial distribution involves the binomial coefficient and accounts for the various ways successes can occur in multiple trials.\n",
    "\n",
    "4. **Parameters:**\n",
    "   - The Bernoulli distribution has a single parameter \\(p\\) representing the probability of success. The Binomial distribution has two parameters: \\(n\\) (the number of trials) and \\(p\\) (the probability of success in each trial).\n",
    "\n",
    "In summary, the Bernoulli distribution is a special case of the Binomial distribution where the number of trials (\\(n\\)) is equal to 1. The Binomial distribution generalizes the concept to multiple independent trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a8c9344-11bf-4b88-bde9-31aa2e780117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'15.87 %'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6.\n",
    "from scipy.stats import norm\n",
    "def ztest(x,mean,std):\n",
    "    a = (x-mean)/std\n",
    "    probability=1-norm.cdf(a)\n",
    "    return str(round(probability*100,2))+\" %\"\n",
    "\n",
    "ztest(60,50,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3535800-c9be-4458-b067-e29899747382",
   "metadata": {},
   "source": [
    "#7\n",
    "The uniform distribution is a probability distribution in which all values of a random variable are equally likely to occur. In other words, every possible outcome has the same probability of occurring, and the probability density function (PDF) is constant within the range of possible values. The uniform distribution is often denoted as \\( U(a, b) \\), where \\( a \\) and \\( b \\) are the minimum and maximum values in the range.\n",
    "\n",
    "The probability density function of a uniform distribution is given by:\n",
    "\n",
    "\\[ f(x) = \\frac{1}{b - a} \\]\n",
    "\n",
    "for \\( a \\leq x \\leq b \\), and \\( f(x) = 0 \\) elsewhere.\n",
    "\n",
    "Here, \\( a \\) is the minimum value in the range, \\( b \\) is the maximum value, and \\( f(x) \\) is the probability density function.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Consider a situation where a fair six-sided die is rolled. The outcome of the die roll can be modeled using a uniform distribution because each of the six possible outcomes (1, 2, 3, 4, 5, 6) is equally likely.\n",
    "\n",
    "In this case, the uniform distribution is \\( U(1, 6) \\), where \\( a = 1 \\) is the minimum value (the lowest possible roll), and \\( b = 6 \\) is the maximum value (the highest possible roll).\n",
    "\n",
    "The probability density function for this uniform distribution is:\n",
    "\n",
    "\\[ f(x) = \\frac{1}{6} \\]\n",
    "\n",
    "for \\( 1 \\leq x \\leq 6 \\), and \\( f(x) = 0 \\) elsewhere.\n",
    "\n",
    "This means that the probability of getting any specific outcome (1, 2, 3, 4, 5, or 6) is equal to \\( \\frac{1}{6} \\), and the probabilities are uniform across all possible outcomes.\n",
    "\n",
    "In summary, the uniform distribution is a simple and intuitive probability distribution where all outcomes are equally likely over a specified range. It is commonly used in various fields, including statistics, physics, and computer science, to model situations where randomness and equality of outcomes are appropriate assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d249f2-ef93-41e0-902d-bcd1891c42c8",
   "metadata": {},
   "source": [
    "#8\n",
    "**Z-Score:**\n",
    "\n",
    "The z-score, also known as the standard score, is a measure that quantifies the number of standard deviations a data point is from the mean of a dataset. It is expressed as:\n",
    "\n",
    "\\[ z = \\frac{x - \\mu}{\\sigma} \\]\n",
    "\n",
    "where:\n",
    "- \\( x \\) is the individual data point,\n",
    "- \\( \\mu \\) is the mean of the dataset,\n",
    "- \\( \\sigma \\) is the standard deviation of the dataset.\n",
    "\n",
    "The z-score indicates how far a particular data point deviates from the mean in terms of standard deviations. A positive z-score means the data point is above the mean, and a negative z-score means it is below the mean.\n",
    "\n",
    "**Importance of Z-Score:**\n",
    "\n",
    "1. **Standardization:**\n",
    "   - Z-scores provide a standardized way of comparing and interpreting scores from different distributions. This allows for a common scale, facilitating comparisons between variables with different units or distributions.\n",
    "\n",
    "2. **Identifying Outliers:**\n",
    "   - Z-scores help identify outliers in a dataset. Extreme z-scores (far from zero) may indicate data points that are unusual or potentially problematic.\n",
    "\n",
    "3. **Normal Distribution Analysis:**\n",
    "   - In a standard normal distribution (with mean 0 and standard deviation 1), z-scores directly correspond to percentiles. A z-score of 1.96, for example, corresponds to the 97.5th percentile, which is often used in confidence interval calculations.\n",
    "\n",
    "4. **Hypothesis Testing:**\n",
    "   - Z-scores are commonly used in hypothesis testing. They help determine whether an observed value is statistically significant, suggesting whether the null hypothesis should be rejected.\n",
    "\n",
    "5. **Data Transformation:**\n",
    "   - Z-scores are used in various statistical analyses, especially when the assumption of normality is important. Transforming data into z-scores can make it easier to interpret and compare.\n",
    "\n",
    "6. **Quality Control:**\n",
    "   - In fields such as manufacturing, z-scores can be used in quality control to identify products or processes that deviate significantly from the mean.\n",
    "\n",
    "7. **Predictive Modeling:**\n",
    "   - In predictive modeling and machine learning, z-scores are often used to standardize features, ensuring that all variables have the same scale and preventing certain features from dominating the model due to their larger scale.\n",
    "\n",
    "In summary, the z-score is a valuable statistical tool that aids in the interpretation and comparison of data by standardizing values and providing a common scale. It is widely used in various statistical analyses and applications across different fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5c89a9-b639-4614-a0e2-1dd5aa1e5a95",
   "metadata": {},
   "source": [
    "#9.\n",
    "The Central Limit Theorem (CLT) is a fundamental concept in statistics that describes the distribution of sample means (or other sample statistics) from any population, regardless of the shape of the original population distribution. The key idea is that as the sample size increases, the distribution of the sample means approaches a normal distribution, even if the population distribution is not normal.\n",
    "\n",
    "The Central Limit Theorem can be stated as follows:\n",
    "\n",
    "If \\(X_1, X_2, ..., X_n\\) is a random sample of size \\(n\\) taken from any population with a mean \\(μ\\) and a finite standard deviation \\(σ\\), then the distribution of the sample means approaches a normal distribution as \\(n\\) approaches infinity, regardless of the shape of the original population distribution.\n",
    "\n",
    "**Significance of the Central Limit Theorem:**\n",
    "\n",
    "1. **Normal Approximation:**\n",
    "   - The CLT allows statisticians to assume that the sampling distribution of the sample mean is approximately normal for large sample sizes. This is valuable because many statistical methods and tests are based on the assumption of normality.\n",
    "\n",
    "2. **Inference on Population Parameters:**\n",
    "   - The CLT is the foundation for making inferences about population parameters based on sample statistics. It forms the basis for confidence intervals and hypothesis testing.\n",
    "\n",
    "3. **Sample Size Determination:**\n",
    "   - The CLT is used in determining the required sample size for estimating population parameters with a desired level of precision. It helps in deciding how large a sample is needed to make reliable statistical inferences.\n",
    "\n",
    "4. **Population Distribution Irrespective:**\n",
    "   - The CLT is powerful because it doesn't require any assumption about the shape of the population distribution. Even if the original population is not normal, the distribution of the sample means tends to be normal for sufficiently large sample sizes.\n",
    "\n",
    "5. **Statistical Process Control:**\n",
    "   - In quality control and manufacturing, where continuous monitoring of processes is crucial, the CLT allows practitioners to use the normal distribution for making decisions about process stability and capability.\n",
    "\n",
    "6. **Means of Averaging:**\n",
    "   - The CLT explains why averages or means tend to be normally distributed, even if the underlying data is not. This is a key reason why statistical methods involving means are widely applicable.\n",
    "\n",
    "7. **Real-World Applications:**\n",
    "   - The CLT is applied in various fields such as finance, biology, psychology, and more. It underlies statistical analyses in diverse areas where making inferences from samples to populations is essential.\n",
    "\n",
    "In essence, the Central Limit Theorem is a foundational concept that extends the applicability of normal distribution-based statistical methods to a wide range of situations, making statistical inference more robust and widely applicable in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18646b69-6989-48e5-ac69-fe38d18eb77d",
   "metadata": {},
   "source": [
    "#10.\n",
    "The Central Limit Theorem (CLT) is a powerful statistical concept, but it relies on certain assumptions to hold true. Here are the key assumptions of the Central Limit Theorem:\n",
    "\n",
    "1. **Random Sampling:**\n",
    "   - The data must be collected through a process of random sampling. Each individual in the population has an equal chance of being selected, and the selection of one individual does not affect the selection of another.\n",
    "\n",
    "2. **Independence:**\n",
    "   - The sampled observations must be independent of each other. This means that the value of one observation should not influence or be influenced by the value of another observation in the sample.\n",
    "\n",
    "3. **Sample Size:**\n",
    "   - The sample size should be sufficiently large. While there is no strict rule about what constitutes a \"sufficiently large\" sample size, a common guideline is that \\(n \\geq 30\\) is often considered adequate. However, in some cases, smaller sample sizes may be acceptable if the underlying population distribution is close to normal.\n",
    "\n",
    "4. **Population Distribution:**\n",
    "   - The Central Limit Theorem makes no assumptions about the shape of the population distribution from which samples are drawn. However, for small sample sizes, the original population distribution should not be heavily skewed.\n",
    "\n",
    "5. **Finite Variance:**\n",
    "   - The population from which the samples are drawn should have a finite variance (\\(σ^2\\)). If the population variance is infinite, the convergence to a normal distribution might be slower, and other distributions (such as the t-distribution) may be more appropriate.\n",
    "\n",
    "It's important to note that while the Central Limit Theorem is quite robust and widely applicable, violating these assumptions can affect the validity of its conclusions. In practice, if the sample size is large enough, the CLT can still provide reasonably accurate approximations even if some of these assumptions are not strictly met. However, researchers and practitioners should be aware of these assumptions and assess their data accordingly. Additionally, in cases where the population distribution is known to be highly non-normal, alternative statistical methods may be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e43519-2e66-4758-a726-f581ece7c117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
